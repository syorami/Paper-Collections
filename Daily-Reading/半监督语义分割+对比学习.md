# 半监督语义分割 + 对比学习

这两天主要在看了下对比学习的相关工作，正好之前看到了两篇半监督语义分割+对比学习的论文，做一下简单的总结。两篇工作为：

* Semi-Supervised Semantic Segmentation with Pixel-Level Contrastive Learning from a Class-wise Memory Bank. ArXiv 2021.
* Semi-supervised Semantic Segmentation with Directional Context-aware Consistency. CVPR 2021.

## 对比学习

对比学习（contrastive learning）算是最近几年比较火热的研究方向之一了，典型的方法有 SimCLR[3] 系列、MoCo[4] 系列以及 BYOL[5] 等，各种方法之间相互借鉴又互有创新，并且在下游的 imagenet 分类任务上已经可以超过全监督的性能，并且在探索在其他视觉任务比如检测和分割上的效果，属实是推动了大家对计算机视觉领域的热情。

众所周知，全监督任务的典型问题在于对大量数据标注的需求，而数据标注所需要的人力物力以及时间等开销是非常庞大的，有多少智能就有多少人工，所以研究者们将视线放到了如何利用大量的无标签样本上。半监督是综合利用标注样本和无标注样本进行训练提升模型性能的一种方法，而自监督则是完全不需要标注样本，使用大量的无标注样本根据定义的 pretext task 来进行无监督训练，再利用从图像中学到的潜在表征知识，在下游任务中去 finetune，来达到知识迁移的目的。

详细的就不多介绍了，这里的重点也不是自监督任务。

## 半监督语义分割

去年调研的时候半监督语义分割的工作还不是很多，大部分方法还是和分类任务差不多，基本就是利用一些常用的半监督组件 mean teacher、强弱扩增或者 co-training 之类的方法，有一部分工作[6]探索了分割任务和分类任务的不同，从扩增方式上做了些改进还是挺有意思的。这次主要介绍的是最近看到的利用自监督任务中常用的对比学习方法去提升半监督分割性能的工作，把自监督的架构融合到了半监督框架中，和之前的一篇 supervised contrastive learning[7] 放在一起看的话倒是有种可以将全监督、半监督和自监督统一到同一个框架中的可能。

### CMB (Class-wise Memory Bank)

### DCC (Directional Context-aware Consistency)

## 相关文献

[1] Semi-Supervised Semantic Segmentation with Pixel-Level Contrastive Learning from a Class-wise Memory Bank. ArXiv 2021.

[2] Semi-supervised Semantic Segmentation with Directional Context-aware Consistency. CVPR 2021.

[3] A Simple Framework for Contrastive Learning of Visual Representations. ICML 2020.

[4] Momentum Contrast for Unsupervised Visual Representation Learning. CVPR 2020.

[5] Bootstrap your own latent: A new approach to self-supervised Learning. NIPS 2020.

[6] Semi-Supervised Semantic Segmentation with Cross-Consistency Training. CVPR 2020.

[7] Supervised Contrastive Learning. NIPS 2020.