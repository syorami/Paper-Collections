# 半监督检测研究进展

最近整理下关于半监督检测的最新相关文章，作为个人总结归纳一些思路和想法，虽然是主要介绍半监督检测的算法，但是会涉及到一些半监督学习的基本概念。

## 什么是半监督学习？

半监督学习旨在利用少量的标注数据和大量的无标注数据进行模型训练，用于提升模型的训练性能和泛化性能。与半监督相对应的是监督学习（利用标注数据进行训练）和自监督/无监督学习（只利用无标注数据），在监督学习已经逐渐使得模型达到性能瓶颈的时候，如何利用更多的无标注数据来进一步挖掘潜在的知识就成了重点。相比于自监督的方案，半监督学习则是相对更加可靠有效解决方案，同时可以节省标注数据所需的时间成本和人力成本。

半监督学习目前尚无完备的理论基础，其有效的必要条件是在输入空间中，潜在的边缘分布概率 <img src="https://www.zhihu.com/equation?tex=p%28x%29" alt="p(x)" class="ee_img tr_noresize" eeimg="1"> 中包含与后验概率 <img src="https://www.zhihu.com/equation?tex=p%28y%7Cx%29" alt="p(y|x)" class="ee_img tr_noresize" eeimg="1"> 相关的信息，如果这个条件也无法达到的话加入额外的无标签数据就无法提升半监督的性能。基于上述的必要条件，半监督学习中有三个重要的假设：

-   平滑假设（smoothness assumption）：如果两个样本在输入空间中相似，其标签也应该相似；
-   聚类假设（low-density assumption）：分类器的决策边界不应该穿过输入空间中的低密度区域；
-   流形假设（manifold assumption）：同一个低维流形（manifold）上的样本应该包含相同的标签；

其中平滑假设和聚类假设是目前相关方案中用的最多的基本假设，特别是在基于扩增扰动的一致性约束方案中。除了这三种基本假设外，还有一些如聚类假设等，其主要目的都是用于刻画数据之间的相关性，即描述边缘分布概率 <img src="https://www.zhihu.com/equation?tex=p%28x%29" alt="p(x)" class="ee_img tr_noresize" eeimg="1"> 的特点，来以此学习后验概率分布 <img src="https://www.zhihu.com/equation?tex=p%28y%7Cx%29" alt="p(y|x)" class="ee_img tr_noresize" eeimg="1"> 。

相关的半监督方案基本都会基于上述假设来介绍自己的motivation，让自己看起来比较师出有名，但是由于没有完备扎实的理论基础在，半监督实际的效果则是见仁见智，甚至很多实际涨点的部分都不是来自于文中claim的方法，另外工业界和学界的半监督设置上还存在较多的不同，这个后面再做介绍。

## 半监督学习常用范式

半监督学习是研究很久的一个领域，在深度学习时代之前就已经有了很多实用方法，例如基于伪标签的方案（self-trainng、co-training、boosting）、基于聚类的方法、基于流形的方法以及基于图的方法，各个方法之间互有交叉。而在深度学习时代，由于神经网络的特征提取器强大的能力，目前见到最多的训练范式主要是自训练（self-training）以及一致性约束（consistency regularization）的方案，以分类任务中的 Noisy Student [1] 和 FixMatch [2] 两种方法为例，简单介绍下这两种常用范式的异同：

![Noisy Student方法示意图](https://cdn.jsdelivr.net/gh/syorami/Paper-Collections@main-md2zhihu-asset/半监督检测研究进展/62025126247e748f-noisy-student.png)

Noisy Student 是典型的自训练方案，其主要特点是方案分为三步：

-   利用有标注数据训练一个基线教师模型；
-   利用基线模型在无标签数据上进行预测推断（这里可能会用到 TTA 等方法），利用置信度对伪标签进行筛选，剔除低置信度的错误预测结果；
-   将筛选后的伪标签加入到与标注数据一起进行监督训练学生模型（可能会用到强弱扩增等）；

上述过程可以通过加载上一次训练好的学生模型作为新的教师模型来重复多轮，即迭代自训练（iterative self-training），就比如 Noisy Student 中利用到 dropout、stochastic depth 等方案提供噪声来使得每轮学到的模型能尽可能的鲁棒，但是通常来说除了第一轮外，重复训练带来的性能增益是边际效应递减的，后续不会带来明显的指标提升，而且多轮训练还很有可能引入 confirmation bias 等问题，大多数方法只进行了一轮训练点到即止。

![FixMatch方法示意图](https://cdn.jsdelivr.net/gh/syorami/Paper-Collections@main-md2zhihu-asset/半监督检测研究进展/6708ab7cb44bab88-fixmatch.png)

一致性约束也是教师-学生模型的训练范式，但是和自训练中教师模型的伪标签固定不变的方法不同，一致性约束方案中的教师模型采用 EMA 学生模型[3]，即学生模型权重的滑动平均，可以在参数空间中起到平滑优化路线的作用[4]，和优化器中的梯度估计部分是一个道理。

一致性约束方案的另一个关键要素在于强弱扩增，对教师模型进行弱扩增（基本的仿射变换）得到预测结果，通过置信度筛选后得到伪标签用于学生模型的训练，而学生模型的输入图像则是强扩增的图像（除基本的仿射变换外还加入很多如colorjitter、cutout、cutmix等强变换），弱扩增是用于得到稳定高质量的伪标签，而强扩增一方面是希望学生模型学到的分离超平面不超过高密度区域（低密度假设和平滑假设），另一方面是避免学生过拟合到错误的伪标签中。

一致性约束方案很多工作都基于扩增展开，这也给半监督学习方法的对比带来了困难，毕竟你很难知道究竟涨点是由于非常tricky的扩增导致的，还是某一项特定的方案改进导致的，而很多扩增方法又是和任务比较强相关的，缺乏泛用性。

除了上述两类方案外，还有许多其他的方法成功应用在半监督分类任务中，如co-training、meta-learning等，但是由于各种各样的原因（计算量、泛用性）应用的不是特别广泛，因此不做过多介绍。

## 半监督目标检测

上面介绍了分类的两种典型的方案，对于半监督目标检测，由于目标检测任务的复杂性，相关研究起步的相对较晚，也是最近两年才有了一些不错的研究工作，并且大体上也是按照这两类方法展开的，接下来对部分工作做一些介绍整理，不深入到细节，只讲下具体的思路和 motivation，感兴趣的可以去 follow 下原文，都不是特别难。

### 自训练方案

#### STAC

![STAC方法示意图](https://cdn.jsdelivr.net/gh/syorami/Paper-Collections@main-md2zhihu-asset/半监督检测研究进展/0a0e8333dfa4a4bb-stac.png)

STAC 是比较早提出的半监督目标检测方案[5]，而且实验中采用的是二阶段 Faster RCNN，因此现在论文中进行方法对比都会拿 STAC 方法来开刀。STAC 的方案就是非常典型的自训练方案框架：

-   在有标签数据上训练教师模型；
-   用训练好的教师模型在无标签数据上生成伪标签；
-   将筛选后的无标签数据加入到训练数据中，训练中对无标签数据进行强扩增，并计算无标签损失训练训练检测器；

STAC 强扩增加入了色彩扩增、全局的坐标变换以及 box 级的变换，论文里对各种因素的消融对比还是比较详细的，整体思路比较基础简单。

#### RPL

![RPL方法示意图](https://cdn.jsdelivr.net/gh/syorami/Paper-Collections@main-md2zhihu-asset/半监督检测研究进展/2cedbcbb4c4af11f-rpl.png)

文中[6]没有定义该方法的名字，暂且取首字母为RPL（Rethinking Pseudo Labels），这篇文章的主要出发点为：1）筛选检测框伪标签利用的是分类（classification）的置信度，无法反映出定位（localization）的精度；2）目标检测中存在较为严重的类别不均衡的问题。

针对第一个问题，RPL提出的解决方案是将回归问题转化成一个分类问题，通过将图像的长边和短边均匀的分为K段，训练一个分类head对检测框的四个边所处的位置进行分类预测，这个分类任务的标注类别就是gt检测框的四个边在所处的线段位置，得到的坐标分类置信度均值与原本的检测分类置信度一起相乘，这样指标既可以反映出检测器分类的准确度，也可以反映出坐标框回归的定位精度。另外，为了增加定位精度，RPL额外训练了一个回归损失对回归坐标做更精细的修正。

针对第二个问题，RPL则是对不同类别的伪标签置信度以及加权权重按照图像中前背景的数量进行了重新计算，使得前景数量少的类别置信度阈值更小、损失权重更大，缓解类别不均衡的问题。

RPL的方案思路主要还是从目标检测任务的角度展开，针对定位和类别不均衡的问题做出了改进优化。

#### DUMG

![image-20220120153709043](https://cdn.jsdelivr.net/gh/syorami/Paper-Collections@main-md2zhihu-asset/半监督检测研究进展/a7760c6ccf4f6d9f-dumg.png)

DUMG[7]方法针对的是迭代自训练中检测模型过拟合伪标签中的高置信度噪声而导致的性能退化问题，采用了一种多阶段的课程学习的方法，先学习简单样本再学习复杂样本来减少对噪声的拟合，最终的预测结果是多个阶段的模型融合结果，有点类似于boosting的方法。

实验的motivation是很合理的，我们在自己的实验对比中也观察到了类似的现象，用上一轮的半监督模型生成伪标签并重复训练有性能下降的情况（实际上如果换成是从Imagnet初始化的参数重新训练而不是加载上一轮的半监督模型，这样的情况就不会存在了，所以个人认为更多的是在已经有偏的模型参数下继续训练导致的优化错误），文章中的重点在于解决带噪难例样本对训练的影响。

文中采用不确定衡量筛选样本，第一个是图像级的不确定度，也就是用所有检测框的平均置信度作为指标排序筛选，第二个是区域级，通过训练中对样本进行权重加权来减少噪声的影响，但是这部分的处理加入的东西有点太多了，而且额外引入了好几个超参数，消融实验中也没有对具体的几个不确定指标进行对比，有一些借鉴意义但不是很实用。

实验对比基本都在VOC上进行，所以也没有办法和其他多数方法进行横向对比。

### 一致性约束方案

#### Unbiased Teacher

![unbiased-teacher方法示意图](https://cdn.jsdelivr.net/gh/syorami/Paper-Collections@main-md2zhihu-asset/半监督检测研究进展/19037f4c4f63fcbb-unbiased-teacher.png)

Unbiased Teacher[8]采用的一致性约束训练范式，和半监督分类的方法基本没有特别大的区别，采用的教师-学生训练，教师是学生模型参数的EMA，也采用了强弱扩增，弱扩增输入到教师用于生成伪标签，强扩增用于学生模型训练。

其他的几个优化的地方，第一个是引入burn-in阶段，在前期只进行监督训练，提升初始伪标签的质量，第二个是针对检测任务类别和前背景不平衡的问题，采用了Focal Loss代替交叉熵损失用于训练RoI分类损失，使得模型可以专注于稀有类别和难例样本。另外有一个细节的处理是考虑到置信度没有反应定位精度，所以不计算伪标签的回归损失，不过这个好像用处不是特别大。总体来说，和分类中一样是典型的一致性约束范式，对检测任务做了部分修改。

#### Instant Teaching

![instant-teaching方法示意图](https://cdn.jsdelivr.net/gh/syorami/Paper-Collections@main-md2zhihu-asset/半监督检测研究进展/5bab14b55ce16da9-instant-teaching.png)

Instant-Teaching[9]同样采用了EMA教师和强弱扩增，不同的是扩增方式换成了Mixup和Mosaic扩增，用于缓解过拟合的问题。Instant-Teaching*则是在Instant-Teaching的基础上增加了co-rectify方案，co-rectify其实就是一个典型的single-view co-training方法，用两个模型互相交同时保证两个模型存在一定的差异，文中用了两种方法，第一个是不同的初始化参数，第二个是两个模型的预测框会作为proposal输入到另一个模型中进行refine和平均。个人来看的话整体方案的创新点并不是很多。

#### Soft Teacher

![soft-teaching方法示意图](https://cdn.jsdelivr.net/gh/syorami/Paper-Collections@main-md2zhihu-asset/半监督检测研究进展/7e5cba1c375ce660-soft-teacher.png)

Soft Teacher[10]这篇文章很有意思，是微软和白翔老师完成的一篇工作。Soft Teacher也是一致性约束范式，针对半监督检测中的两个问题提出了改进，第一个问题是高置信度阈值带来的伪标签中低检出的问题，提出了Soft Teacher的机制，也就是在计算学生模型训练损失时，用学生模型预测的检测框在教师模型中的预测分数作为一个权重进行加权，相当于硬标签变软了。第二个问题是高置信度无法反应定位精度的问题，提出了box jitter的方法，对教师模型的预测伪标签进行多次扰动，并重新将其作为proposal输入到教师模型中得到坐标框，并计算其四个坐标的变化方差，根据方差筛选稳定的预测框作为回归损失的计算。

这篇文章有意思的点在于，这两个claim的创新点从分析和实验上都是比较合理的，但在我自己实验对比的时候如果去掉这两个改进的部分，并稍微放松一点置信度阈值，也可以达到实验中的性能效果，第二个是在另一个不同的数据集上无法观察到坐标方差和IoU指标之间的相关关系，Soft Teacher的SOTA性能指标究竟是来自于提出的改进部分，还是来自于更strong的codebase有待更多的探究分析。不过个人更多的感觉这样的改进属于是在一个复杂的优化空间中找到了一个相对可靠的局部最优解，可能另一个优化路线也可以达到同样的效果，或者换一个任务后同样的解法就无效了，但是这样的方案仍然很有启发意义。

## 总结分析

其他的半监督检测文章还有很多，这里只列出来了一部分。从半监督学习的角度来看，半监督检测和半监督分类没有特别大的区别，自训练和一致性约束方案的训练范式基本相同，也都采用了强弱扩增的方法来进行扰动，目标检测任务更多的关注到检测任务本身的特点，针对类别不均衡、前背景均衡以及定位等问题做出相应的改进，并结合半监督学习方法提升学习性能，这些都是比较实际的改进方向，从扩增的角度来做的话个人感觉并不是特别能泛化到其他任务上。半监督分割任务也是类似，重点可以放在如何结合语义分割任务的特点对半监督方案进行改进优化。

除了这些已经介绍到的一些外，目前还有比较热门的则是结合自监督和半监督方法用于训练，也是刷新了很多SOTA的指标，不过这类方法更多的还是偏向于如何利用无标签数据进行自监督，在半监督方法的应用和创新上都比较有限，而且由于见到了更多的数据，算是对半监督方法的一种降维打击吧。

另外，从学界和工业界的角度来看的话，半监督方案又有一些差别，学界采用的教师学生模型其实还是同一个模型，而工业界由于没有计算量等限制，从提升半监督性能的角度来说的话训练一个超大的教师模型来预测伪标签指导学生模型学习更加实用简单，举例来说训练一个见过大量数据的 SwinTransformer 去预测伪标签指导 ResNet18 小模型训练，肯定比 ResNet18 来自己教自己更靠谱、性能提升更多，理论上来说只要教师模型性能足够高，这样的方式可以逼近全监督性能。这种情况下的训练类似于蒸馏方案，所以还有半监督蒸馏相关的研究。工业界落地需要考虑更多复杂的情况，比如 OOD 样本的影响、某个特定关注的指标等，这个时候半监督方案需要更多的集中在特定伪标签筛选策略上，强调的是某个任务场景下的专用性，这也和学界方案的通用性存在一定的gap。

整体来说，半监督学习是非常实用有效的方案，只要无标签数据和有标签数据存在差异的情况下（即无标签数据的存在可以丰富我们对于数据边缘分布概率的理解），基本上我们就可以期望半监督学习对模型指标有所提升，在实际落地的情况下，学界的方案不完全实用但有一定的参考价值。

## 相关文献

[1] Self-training with Noisy Student improves ImageNet classification. CVPR 2020.

[2] FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence. NIPS 2020.

[3] Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results. NIPS 2017.

[4] There Are Many Consistent Explanations of Unlabeled Data: Why You Should Average.ICLR 2019.

[5] A Simple Semi-Supervised Learning Framework for Object Detection. ArXiv 2020.

[6] Rethinking Pseudo Labels for Semi-Supervised Object Detection. ArXiv 2021.

[7] Data-Uncertainty Guided Multi-Phase Learning for Semi-Supervised Object Detection. CVPR 2021.

[8] Unbiased Teacher for Semi-Supervised Object Detection. ICRL 2021.

[9] Instant-Teaching: An End-to-End Semi-Supervised Object Detection Framework. CVPR 2021.

[10] End-to-End Semi-Supervised Object Detection with Soft Teacher. ICCV 2021.



Reference:

